# 1.1 어휘분석이란? Token이란?

## 이번에 할 것

- Lexical Analysis (어휘분석)
- Token 이란?
- 어휘분석을 위해, token을 어떻게 기술할 것인가?

### 컴파일러 전반부 Structure

![image](https://github.com/user-attachments/assets/5b1e4dd0-7bcc-4003-b3c4-0739b3a5dc77)

컴파일러는 전체적으로, 소스코드가 들어오면 전처리 과정을 거친다. 전처리 과정을 거치고 나면, #include, #define 등이 사라지게 되고 그 자리에 c코드가 들어가는 형태인 전처리된 소스코드가 된다.

그 후에는 어휘, 구문, 의미의 세 가지 분석 단계를 거치게 된다. 세 분석을 거치고 나온 것이 중간 코드이며, 중간 코드로 나오기 직전 추상 구문 트리 형태를 거친다. 

## Lexical Analysis (어휘분석)

![image](https://github.com/user-attachments/assets/4817ee32-43be-45be-b9b8-95cc70550a5f)

어휘 분석이란, 입력된 원시프로그램을 긴 문자열로 보고, 차례대로 한 문자씩 검사하여, 이것을 '의미상으로 가장 최소의 단위'로 쪼개주는 것을 의미한다.

만약 
```
if (b == 0) a = b;
```
이라는 문장이 있다면, `if`가 하나의 키워드이므로 한 덩어리, `(` 한 덩어리, `b` 라는 식별자 한 덩어리, 같다는 의미의 `==` 한 덩어리. 이런 식으로 의미상으로 가장 작은 것들을 한 덩어리씩 뜯어서 배열과 같은 부분에 한 셀에 하나씩 집어넣는다. 이 한 셀에 들어간 것을 가르켜 Token이라고 한다. 

이렇게 문자열을 토큰으로 변환하는 과정이 바로 어휘분석기가 하는 일인데, 변환 과정에서 줄어드는 것이 있다. space나 new line과 같은 것들이 전부 빠지게 된다. 그래서 결과적으로는 코드의 크기가 줄어든다고 하기도 한다.

## 토큰 (Token)

![image](https://github.com/user-attachments/assets/a726415d-ef2e-4155-b7b5-90a37cd65a78)

토큰에 대해 더 살펴본다면, '문법적으로 의미 있는 최소단위'를 얘기한다. 

먼저 식별자, 키워드, 상수, 연산자들 (덧셈 곱셈 등), 심볼들 (여는괄호 닫는괄호 등) 을 다 토큰이라고 본다. 문자열도 커다랗게 하나의 덩어리로 봐 토큰이라고 생각한다. 문자열에서는 예에서와 같이 역슬래쉬(\)를 이용해 쌍따옴표 등을 처리할 수 있다. 그래서 이런 문자열을 한꺼번에 하나의 토큰으로 보고 있다. 

그리고 또 하나는, 토큰의 종류는 이미지와 같이 5가지 종류가 있다. 그런데 이 중에서 성격이 조금 다른 두 가지가 있다. 바로 식별자하고 상수가 조금 성격이 다르다. 다르다는 것이 다른 식별자에 비해 조금 더 처리해야 할 부분이 있다는 의미이다. 문자열은 문자열 상수라고 분류해서 상수 속에 포함하는데, 이렇게 되면 크게 `키워드, 연산자 부분`과 `식별자, 상수, 문자열 부분` 이렇게 두 가지로 갈라지게 된다. 

우리가 흔히 키워드나 연산자를 처리할 때는, 키워드의 경우 만약 `i`가 나오고 그 다음 `f`가 나온다면 `if`구나 라고 생각을 한다. 연산자면 더하기 심볼(+)이 나오면 더하기구나 라고 생각을 한다. 이렇게 정확하게 `i`가 나오고 `f`가 나오는, 다시말해 exact match라고 부르는 정확한 매치에 해당하는 것들은 어디까지가 하나의 토큰인지 판단하기 편하다.

그런데 식별자나 상수, 문자열은 어디까지가 토큰인지를 알아보기도 힘들기 때문에 추가적으로 신경을 써줘야 한다. 그래서 이를 표현하기 위해 다른 도구들을 사용해야 하기 떄문에, 몇 가지 깊이있는 내용들을 배워야 하는 상황이 된다.

### 참고) StringTokenizer in Java

![image](https://github.com/user-attachments/assets/2aab8ab3-e7f2-4c53-aaa7-97880fdb94ba)

java.util은 보통 굉장히 핵심적인 것들이 모여있다. 즉, java.util에 존재하는 Tokenizer는 많이들 사용하는 것이다. 

Tokenizer의 기본적인 동작으로는, 어떤 string을 하나 받아 str 변수에 넣는다. 이를 이용해 stringtokenizer이라는 객체를 하나 만든다. 이후 counttokens와 nexttoken을 통해 동작한다. 

토크나이저가 하는 역할은 문자열 사이사이에 있는 공백을 이용해 문자열을 잘라주는 것이다. 예를 들어 `this is my string` 라는 문자열을 `this`, `is`, `my`, `string` 의 네 개의 토큰으로 자르고, 네 개의 토큰이 각각 string으로 들어가게 된다. 이런 식으로 문자열을 토큰으로 잘라주는 역할을 하는 것이 string tokenizer이다.

## Token 과 관련된 질문들

방금전에 봤던 Tokenizer를 이용하면 연산자, 키워드와 같이 exact match일 경우에는 얼마든지 쉽게 처리가 가능하다. 하지만 그 밖의 식별자, 상수를 표현할 떄는 한계가 있다. 그런 것에 관해서 어떤 식으로 처리해야 할 지 고민했을 때, 네 가지 정도의 질문이 나오게 된다.

1. How to describe tokens?
    * 프로그래밍 언어 제작자가 토큰 하나하나를 기술(설명)하는 방법.
   
2. How to recognize tokens?
    * 토큰을 인식해 내는 방법
   
3. How to break up tokens?
    * 여러 토큰이 인식되었을 때 결정하는 방법 (토큰을 어떻게 자를지)
   
4. How to represent tokens?
    * 토큰이 컴퓨터에서 표현되는 방법
